<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint">
  <meta name="keywords" content="GAN, GAN Inversion, Latent space editing">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/madscientist.jpg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://kumapowerliu.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/kristen-rang/FFCLIP">
            FFCLIP
          </a>
          <a class="navbar-item" href="https://github.com/KumapowerLIU/DeFLOCNet">
            DeFLOCNet
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://kumapowerliu.github.io">Hongyu Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ybsong00.github.io/">Yibing Song</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://cqf.io/">Qifeng Chen</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>HKUST,</span>
            <span class="author-block"><sup>2</sup> AI<sup>3</sup>Institute, Fudan University,</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.11448"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.11448"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/KumapowerLIU/CLCAE"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>

            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
            <img src="./static/images/teaser.png"
                 class="teaser-image"
                 alt="Teaser."/>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">CLCAE</span> project the image to the latent and feature space in StyleGAN, and edit the image with SOTA latent space editing methods.
      </h2>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
              GAN inversion and editing via StyleGAN maps an input image into the embedding spaces (W, W<sup>+</sup>, and F)
              to simultaneously maintain image fidelity and meaningful
              manipulation. From latent space W to extended latent
              space W<sup>+</sup> to feature space F in StyleGAN, the editability
              of GAN inversion decreases while its reconstruction quality
              increases. Recent GAN inversion methods typically explore
              W<sup>+</sup> and F rather than W to improve reconstruction fidelity
              while maintaining editability. As W<sup>+</sup> and F are derived
              from W that is essentially the foundation latent space of
              StyleGAN, these GAN inversion methods focusing on W<sup>+</sup>
              and F spaces could be improved by stepping back to W. In
              this work, we propose to first obtain the proper latent code
              in foundation latent space W. We introduce contrastive
              learning to align W and the image space for proper latent code discovery. Then, we leverage a cross-attention encoder to transform the obtained latent code in W into W<sup>+</sup>
              and F, accordingly. Our experiments show that our exploration of the foundation latent space W improves the representation ability of latent codes in W<sup>+</sup> and features in F,
              which yields state-of-the-art reconstruction fidelity and editability results on the standard benchmarks
                        </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->


  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Method. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Contrastive Learning</h2>
          <p>
            To find the proper latent code in W space, we follow the CLIP and propose a <i>contrastive learning</i> based method to align the image space and latent space. After alignment, we set the contrastive
            process as a loss similar to the CLIP to get the proper latent code during inverison.
          </p>
            <img src="./static/images/contrastive.png"
                 class="contrastive-image"
                 alt="image."/>
        </div>



      <!-- Method. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Pipeline</h2>
          <p>
          The pipeline of our method. With the input image, we first predict the latent code w with feature T<SUB>1</SUB>. The w is constrained
            with the proposed contrastive learning loss. Then two cross-attention blocks take the refined w as a foundation to produce the latent code w<sup>+</sup> and feature f .
          Finally, we send the w<sup>+</sup> to StyleGAN via AdaIN and replace the selected feature in StyleGAN with f to generate the output image
          </p>
            <img src="./static/images/pipeline.png"
                 class="pipeline-image"
                 alt="image."/>
        </div>
      </div>


      <!-- Results. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Results in W<sup>+</sup> space.</h2>
            <img src="./static/images/Results1.png"
                 class="results"
                 alt="image."/>
        </div>
      </div>
            <!-- Results. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Results in F space.</h2>
            <img src="./static/images/Results2.png"
                 class="results"
                 alt="image."/>
        </div>
      </div>

      <!--/ Visual Effects. -->

<!--      &lt;!&ndash; Matting. &ndash;&gt;-->
<!--      <div class="column">-->
<!--        <h2 class="title is-3">Matting</h2>-->
<!--        <div class="columns is-centered">-->
<!--          <div class="column content">-->
<!--            <p>-->
<!--              As a byproduct of our method, we can also solve the matting problem by ignoring-->
<!--              samples that fall outside of a bounding box during rendering.-->
<!--            </p>-->
<!--            <video id="matting-video" controls playsinline height="100%">-->
<!--              <source src="./static/videos/matting.mp4"-->
<!--                      type="video/mp4">-->
<!--            </video>-->
<!--          </div>-->

<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
<!--    &lt;!&ndash;/ Matting. &ndash;&gt;-->

<!--    &lt;!&ndash; Animation. &ndash;&gt;-->
<!--    <div class="columns is-centered">-->
<!--      <div class="column is-full-width">-->
<!--        <h2 class="title is-3">Animation</h2>-->

<!--        &lt;!&ndash; Interpolating. &ndash;&gt;-->
<!--        <h3 class="title is-4">Interpolating states</h3>-->
<!--        <div class="content has-text-justified">-->
<!--          <p>-->
<!--            We can also animate the scene by interpolating the deformation latent codes of two input-->
<!--            frames. Use the slider here to linearly interpolate between the left frame and the right-->
<!--            frame.-->
<!--          </p>-->
<!--        </div>-->
<!--        <div class="columns is-vcentered interpolation-panel">-->
<!--          <div class="column is-3 has-text-centered">-->
<!--            <img src="./static/images/interpolate_start.jpg"-->
<!--                 class="interpolation-image"-->
<!--                 alt="Interpolate start reference image."/>-->
<!--            <p>Start Frame</p>-->
<!--          </div>-->
<!--          <div class="column interpolation-video-column">-->
<!--            <div id="interpolation-image-wrapper">-->
<!--              Loading...-->
<!--            </div>-->
<!--            <input class="slider is-fullwidth is-large is-info"-->
<!--                   id="interpolation-slider"-->
<!--                   step="1" min="0" max="100" value="0" type="range">-->
<!--          </div>-->
<!--          <div class="column is-3 has-text-centered">-->
<!--            <img src="./static/images/interpolate_end.jpg"-->
<!--                 class="interpolation-image"-->
<!--                 alt="Interpolation end reference image."/>-->
<!--            <p class="is-bold">End Frame</p>-->
<!--          </div>-->
<!--        </div>-->
<!--        <br/>-->
<!--        &lt;!&ndash;/ Interpolating. &ndash;&gt;-->

<!--        &lt;!&ndash; Re-rendering. &ndash;&gt;-->
<!--        <h3 class="title is-4">Re-rendering the input video</h3>-->
<!--        <div class="content has-text-justified">-->
<!--          <p>-->
<!--            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel-->
<!--            viewpoint such as a stabilized camera by playing back the training deformations.-->
<!--          </p>-->
<!--        </div>-->
<!--        <div class="content has-text-centered">-->
<!--          <video id="replay-video"-->
<!--                 controls-->
<!--                 muted-->
<!--                 preload-->
<!--                 playsinline-->
<!--                 width="75%">-->
<!--            <source src="./static/videos/replay.mp4"-->
<!--                    type="video/mp4">-->
<!--          </video>-->
<!--        </div>-->
<!--        &lt;!&ndash;/ Re-rendering. &ndash;&gt;-->

      </div>
    </div>
    <!--/ Animation. -->


    <!-- Concurrent Work. -->
<!--    <div class="columns is-centered">-->
<!--      <div class="column is-full-width">-->
<!--        <h2 class="title is-3">Related Links</h2>-->

<!--        <div class="content has-text-justified">-->
<!--          <p>-->
<!--            There's a lot of excellent work that was introduced around the same time as ours.-->
<!--          </p>-->
<!--          <p>-->
<!--            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.-->
<!--          </p>-->
<!--          <p>-->
<!--            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>-->
<!--            both use deformation fields to model non-rigid scenes.-->
<!--          </p>-->
<!--          <p>-->
<!--            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>-->
<!--          </p>-->
<!--          <p>-->
<!--            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.-->
<!--          </p>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->
    <!--/ Concurrent Work. -->


</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{liu2022delving,
  title={Delving StyleGAN Inversion for Image Editing: A Foundation Latent Space Viewpoint},
  author={Liu, Hongyu and Song, Yibing and Chen, Qifeng},
  journal={arXiv preprint arXiv:2211.11448},
  year={2022}
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/abs/2211.11448">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/KumapowerLIU" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
